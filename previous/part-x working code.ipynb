{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6537f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from random import choice\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import LinearColorMapper, BasicTicker, ColorBar\n",
    "from bokeh.palettes import Category10\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern as M, RBF as R, ConstantKernel as C \n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import scipy as sp\n",
    "import numpy.matlib as mtlb\n",
    "from numpy import linalg as la\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "#import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import joblib\n",
    "import shutil\n",
    "from typing import Tuple, Union, List, Callable\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from numpy import arange\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from numpy import asarray\n",
    "from numpy.random import normal\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26a136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/yumengcao/opt/anaconda3/lib/python3.9/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15f2e8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [4, 3]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_u = [[1,4],[2,3]]\n",
    "list(map(list,zip(*sub_u )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eea0a680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 7, 10], [2, 5, 8, 11], [3, 6, 9, 12]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "list(map(list,zip(*a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af9415cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sl(sub_u: list, i_dim: int):  #get the region that we want to do partition\n",
    "\n",
    "    '''\n",
    "    Returns the desired partition region\n",
    "\n",
    "    Parameters:\n",
    "        sub_u (list): M * i_dim * 2 matrix that has the upper and lower bounds\n",
    "        i_dim: the dimension of the subregion\n",
    "    Returns:\n",
    "        [np.ndarray, np.ndarray]: tuple of MxNx1 that are the separated upper and lower bounds\n",
    "    '''\n",
    "    sub_u1 = np.array(sub_u)\n",
    "    assert sub_u1.shape[1] == i_dim, 'sub_u matrix must be i_dim dimensional'\n",
    "    assert sub_u1.shape[2] == 2, 'sub_u matrix must be an M * i_dim * 2'\n",
    "    assert np.apply_along_axis(lambda x: x[1] > x[0], 2, sub_u1).all(), 'sub_u Z-pairs must be in increasing order'\n",
    "    sl_coordinate_lower = sub_u1[:, :, 0]  # Return first Z-value\n",
    "    sl_coordinate_upper = sub_u1[:, :, 1]  # Return second Z-value\n",
    "\n",
    "    return sl_coordinate_lower, sl_coordinate_upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a15ffedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2]]), array([[4, 3]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl(sub_u, i_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8dd760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_sample(X_all, Y_all, sub_r,i_dim,z,s_p,Y_p ):##########################\n",
    "    if k!=0:\n",
    "        for i in range(len(sub_r)):\n",
    "            for m in range(len(X_all)):\n",
    "                TELL = 1\n",
    "                for j in range(i_dim):\n",
    "                      if TELL ==1:\n",
    "                        if X_all[m][j] < sub_r[i][j][1] and X_all[m][j] > sub_r[i][j][0]:\n",
    "                            TELL = 1\n",
    "                        else:\n",
    "                            TELL = 0\n",
    "                #print(TELL)\n",
    "                if TELL == 1:\n",
    "                    s_p[i].append(X_all[m])\n",
    "                    Y_p[i].append(Y_all[m])\n",
    "        return s_p, Y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05619816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c66748f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3600648353.py, line 317)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/wq/5wjbhl5x7zq93d07_4181hsm0000gn/T/ipykernel_5062/3600648353.py\"\u001b[0;36m, line \u001b[0;32m317\u001b[0m\n\u001b[0;31m    level_quantile[i][o] = stats.norm.interval(0.96,mean,std) y_pred_st - norm.ppf(level[o])*sigma_st\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def sl(sub_u: list, i_dim: int):  #get the region that we want to do partition\n",
    "    '''\n",
    "    Returns the desired partition region\n",
    "\n",
    "    Parameters:\n",
    "        sub_u (list): M * i_dim * 2 matrix that has the upper and lower bounds\n",
    "        i_dim: the dimension of the subregion\n",
    "    Returns:\n",
    "        [np.ndarray, np.ndarray]: tuple of MxNx1 that are the separated upper and lower bounds\n",
    "    '''\n",
    "    sub_u1 = np.array(sub_u)\n",
    "    assert sub_u1.shape[1] == i_dim, 'sub_u matrix must be i_dim dimensional'\n",
    "    assert sub_u1.shape[2] == 2, 'sub_u matrix must be an M * i_dim * 2'\n",
    "    assert np.apply_along_axis(lambda x: x[1] > x[0], 2, sub_u1).all(), 'sub_u Z-pairs must be in increasing order'\n",
    "    sl_coordinate_lower = sub_u1[:, :, 0]  # Return first Z-value\n",
    "    sl_coordinate_upper = sub_u1[:, :, 1]  # Return second Z-value\n",
    "\n",
    "    return sl_coordinate_lower, sl_coordinate_upper\n",
    "\n",
    "# def fun_reg_branching(sl_coordinate_lower: np.array, sl_coordinate_upper: np.array, i_dim: int, i_B: int, sub_r, sub_u: list) -> list:\n",
    "#     '''\n",
    "#     Partitioning Algorithm\n",
    "#     Parameters:\n",
    "#         [np.ndarray, np.ndarray]: tuple of MxNx1 that are the separated upper and lower bounds\n",
    "#         i_dim(int):dimension\n",
    "#         sub_u(list): defined region\n",
    "        \n",
    "#     Returns:\n",
    "#         sub_r(list): sub-regions\n",
    "#     '''\n",
    "#     assert sl_coordinate_lower.ndim == 2, 'sl_coordinate_lower matrix must be 2 dimensional'\n",
    "#     assert sl_coordinate_upper.ndim == 2, 'sl_coordinate_upper matrix must be 2 dimensional'\n",
    "#     sl_coordinate_upper = sl_coordinate_upper.tolist()\n",
    "#     sl_coordinate_lower = sl_coordinate_lower.tolist()\n",
    "#     for j in range(len(sub_u)):\n",
    "#         m = (np.array(sl_coordinate_upper[j])-np.array(sl_coordinate_lower[j])).tolist()\n",
    "#         f_value = choice(m)\n",
    "#         i_index = m.index(f_value)\n",
    "#         for i in range(0, i_B):\n",
    "#             l_coordinate_lower = copy.deepcopy(sl_coordinate_lower)\n",
    "#             l_coordinate_upper = copy.deepcopy(sl_coordinate_upper)\n",
    "#             l_coordinate_lower[j][i_index] = float((sl_coordinate_upper[j][i_index] - sl_coordinate_lower[j][i_index]) * i) / i_B + sl_coordinate_lower[j][i_index]\n",
    "#             l_coordinate_upper[j][i_index] = float((sl_coordinate_upper[j][i_index] - sl_coordinate_lower[j][i_index]) * (i + 1)) / i_B + sl_coordinate_lower[j][i_index]\n",
    "#             a = [[0]*2 for i in range(0, i_dim)]\n",
    "#             for i in range(0, i_dim):\n",
    "#                 a[i][0] = l_coordinate_lower[j][i]\n",
    "#                 a[i][1] = l_coordinate_upper[j][i]\n",
    "#             sub_r.append(a)\n",
    "\n",
    "#     return sub_r\n",
    "\n",
    "def tell_sample(X_all, Y_all, sub_r,i_dim,z,s_p,Y_p ):##########################\n",
    "    if k!=0:\n",
    "        for i in range(len(sub_r)):\n",
    "            for m in range(len(X_all)):\n",
    "                TELL = 1\n",
    "                for j in range(i_dim):\n",
    "                      if TELL ==1:\n",
    "                        if X_all[m][j] < sub_r[i][j][1] and X_all[m][j] > sub_r[i][j][0]:\n",
    "                            TELL = 1\n",
    "                        else:\n",
    "                            TELL = 0\n",
    "                #print(TELL)\n",
    "                if TELL == 1:\n",
    "                    s_p[i].append(X_all[m])\n",
    "                    Y_p[i].append(Y_all[m])\n",
    "        return s_p, Y_p\n",
    "\n",
    "    \n",
    "def sample_g(sub_r: list, n: int, i_dim:int) -> np.ndarray:\n",
    "    '''\n",
    "    Sample sub_r n times\n",
    "\n",
    "    Parameters:\n",
    "        sub_r (list): Sample space\n",
    "        n (int): Number of samples\n",
    "        i_dim(int): dimension of the region\n",
    "    Returns:\n",
    "        np.ndarray: Matrix of sampled points\n",
    "\n",
    "    '''\n",
    "    sub_r1 = np.array(sub_r)\n",
    "    assert sub_r1.shape[1] == i_dim, 'sub_r matrix must be 3-dimensional'\n",
    "    assert sub_r1.shape[2] == 2, 'sub_r matrix must be MxNx2'\n",
    "    assert np.apply_along_axis(lambda x: x[1] > x[0], 2, sub_r1).all(), 'sub_r Z-pairs must be in increasing order'\n",
    "\n",
    "    return np.apply_along_axis(lambda x: np.random.uniform(x[0], x[1], n), 2, sub_r1)\n",
    "\n",
    "\n",
    "def sam(sub_r: list, n: int, sample: np.array, s: list,s_p:list) -> np.array:###############\n",
    "    '''\n",
    "    modify the points \n",
    "\n",
    "    Parameters:\n",
    "        sub_r (list): Sample space\n",
    "        n (int): Number of samples\n",
    "\n",
    "    Returns:\n",
    "        np.array: Matrix of sampled points\n",
    "\n",
    "    '''\n",
    "    X_all =[]\n",
    "    for j in range(len(sub_r)):\n",
    "        for i in range(n):\n",
    "            s[j][i] =  sample[j][:, i]\n",
    "        s[j] = s[j] + s_p[j] #################################\n",
    "        X_all += s[j]\n",
    "    s = np.array(s)\n",
    "    return s,X_all\n",
    "\n",
    "\n",
    "def g(s: np.array, Y, test_function,Y_p:list) -> list:  #True values\n",
    "    '''\n",
    "    calculate robustness values\n",
    "\n",
    "    Parameters:\n",
    "        s (np.array): Sample points\n",
    "        test_fucntion (function)\n",
    "\n",
    "    Returns:\n",
    "        list: Matrix of robustness values\n",
    "\n",
    "    '''\n",
    "    Y_all = []\n",
    "    for k in range(0,len(s)):\n",
    "        Y.append([])\n",
    "        for i in range(0,len(s[k])):\n",
    "            current = test_function(s[k][i]) #VECTOR\n",
    "            Y[k].append(current)\n",
    "            Y[k].append(Y_p[k])#############\n",
    "        Y_all +=Y[k]\n",
    "    return Y,Y_all\n",
    "\n",
    "def vol(sub_u:list,i_dim: int) -> int:    #calculate the volume of undefined area\n",
    "    '''\n",
    "    calculate defined regions‘ volume\n",
    "    Parameters:\n",
    "        sub_u(list) :defined regions\n",
    "        i_dim(int) : dimension of these regions\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        int: the volume of that regions\n",
    "\n",
    "    '''\n",
    "    v = 0\n",
    "    for i in range(len(sub_u)):\n",
    "        a = []\n",
    "        for j in range(i_dim):\n",
    "            a.append ((sub_u[i][j][1] - sub_u[i][j][0]))\n",
    "        #print(a)\n",
    "        v += np.prod(a)# * (sub_u[i][2][1] - sub_u[i][2][0])* (sub_u[i][3][1] - sub_u[i][3][0])* (sub_u[i][4][1] - sub_u[i][4][0])\n",
    "    \n",
    "    #print(v)\n",
    "    return v\n",
    "\n",
    "def surrogate(model, X):\n",
    "    '''\n",
    "    predict for the Predicted values of BO\n",
    "    Parameters:\n",
    "        model\n",
    "        X(np.array)\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        predicted values\n",
    "\n",
    "    '''\n",
    "\t# catch any warning generated when making a prediction\n",
    "    with catch_warnings():\n",
    "        # ignore generated warnings\n",
    "        simplefilter(\"ignore\")\n",
    "        return model.predict(X, return_std=True)\n",
    "    \n",
    "def acquisition(X: np.array, Xsamples: np.array, model):\n",
    "    '''\n",
    "    calculate the best surrogate score found so far\n",
    "    Parameters:\n",
    "        model; the GP models\n",
    "        X(np.array): sample points \n",
    "        Xsample(np.array): new sample points for BO\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        sample probabiility of each sample points\n",
    "\n",
    "    '''\n",
    "    # calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = min(yhat)\n",
    "    # calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "    #mu = mu[:, 0]\n",
    "    # calculate the probability of improvement\n",
    "    probs = norm.cdf((mu - best) / (std+1E-9))\n",
    "    return probs\n",
    "\n",
    "def opt_acquisition(X: np.array, y: np.array, model,n_b:int ,i_dim:int, sub_r:list):\n",
    "    '''\n",
    "    get the sample points\n",
    "    Parameters:\n",
    "        X(np.array): sample points \n",
    "        y(np.array): corresponding rebustness values\n",
    "        model: the GP models \n",
    "        n_b(int): the number of sample points to construct the robustness values\n",
    "        i_dim(int): dimesion\n",
    "        sub_r(list): subregions\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "         min_bo(np.array): the new sample points by BO\n",
    "\n",
    "    '''\n",
    "    # random search, generate random samples\n",
    "    samplebo = [[[0]*(n_b)] for m in range(i_dim)]\n",
    "    for k in range(i_dim):\n",
    "        samplebo[k] = np.random.uniform(sub_r[k][0],sub_r[k][1],n_b)\n",
    "    sbo = [[[0]*i_dim] for p in range(n_b)]\n",
    "    for l in range(n_b):\n",
    "        sbo[l] = ([x[l] for x in samplebo])\n",
    "    # calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, sbo, model)\n",
    "    # locate the index of the largest scores\n",
    "    ix = argmax(scores)\n",
    "    min_bo = np.array(sbo)[ix]\n",
    "    return min_bo\n",
    "\n",
    "def Bayesian_optimization(s:np.array , Y:list, n_bo: int, i_dim:int, sub_r:list,test_function,n_b:int):\n",
    "    '''\n",
    "    calculate the best surrogate score found so far\n",
    "    Parameters:\n",
    "        s(np.array): sample points\n",
    "        Y(list): robustness values\n",
    "        n_bo(int): number of Bayesian Optimization sampling\n",
    "        i_dim(int): dimension\n",
    "        sub_r(list): subregions\n",
    "        test_function: the test function\n",
    "        n_b(int): number of points to construct GPs in BO (default = 100)\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        S_BO(np.array): updated sample points\n",
    "        Y(list): corresponding updated robuseness values\n",
    "\n",
    "    '''\n",
    "    s_bo = []\n",
    "    s_bo_all = []\n",
    "    Y_all = []\n",
    "    for i in range(len(s)):\n",
    "        X = s[i]\n",
    "        for j in range(n_bo):\n",
    "            model = GaussianProcessRegressor()\n",
    "            model.fit(X, Y[i])\n",
    "            #print('1')\n",
    "            # select the next point to sample\n",
    "            min_bo = opt_acquisition(X, Y[i], model,n_b,i_dim, sub_r[i])\n",
    "            # sample the point\n",
    "            actual = test_function(min_bo)\n",
    "            # add the data to the dataset\n",
    "            X = vstack((X, [min_bo]))\n",
    "            X = list(X)\n",
    "            Y[i].append(actual)\n",
    "        s_bo.append(X)\n",
    "        s_bo_all += X\n",
    "        Y_all+=Y[i]\n",
    "    s_bo = np.array(s_bo)\n",
    "    return s_bo,Y,s_bo_all, Y_all\n",
    "\n",
    "\n",
    "def model_construction(s: np.array, Y: list, v_s:  int, sub_r: list, lower, upper, level: list, z: int, q: int, i_dim: int, fal_num:int, n_model:int,alpha:float, list_star:list) -> Tuple[np.array,np.array]:   ##Gaussian process \n",
    "    '''\n",
    "    construct Gaussian processes and confidence intervals\n",
    "\n",
    "    Parameters:\n",
    "        s (np.array): Sample points\n",
    "        Y (list): robustness values\n",
    "        v_s (int): volume of sub_u\n",
    "        sub_r(list): partitioned subregions\n",
    "        z(int): # of repliction \n",
    "        q(int): # of iteration\n",
    "        i_dim(int): # of dimension\n",
    "        level(list): the quantiles (example:[0.5,0.6])\n",
    "        fal_num(int): # of points to construct the falsification volume\n",
    "        n_model: # of points to construct thr lower/ upper bounds \n",
    "        alphs(float): mis-coverage level\n",
    "        list_star(list): subregion number\n",
    "    Returns:\n",
    "        model_lower(np.array): lower bounds of confidence intervals of each subregions\n",
    "        model_upper(np.array): lower bounds of confidence intervals of each subregions\n",
    "        models: all GP models corresponding sub-regions\n",
    "    '''\n",
    "    level_quantile = [[0]*len(level) for i in range(len(s))]\n",
    "    for i in range(len(s)):\n",
    "        X = s[i]\n",
    "        y = Y[i]\n",
    "        #kernel = R([1]*i_dim) * M([1]*i_dim) #input kernel for GPs \n",
    "        gp = GaussianProcessRegressor()\n",
    "        gp.fit(X, y) #fit sample points to Grussian Process\n",
    "        name =  '/Users/candicetsao/Desktop/sin_gp/models/'+'trainmodel' +str(0)+ str(q+1) +str(0)+ str(z+1) +str(0)+ str(list_star[i])+'.m'  #save the models # modify your name here\n",
    "        joblib.dump(gp, name) \n",
    "        #model = joblib.load(name)\n",
    "        n_s = int(fal_num*vol([sub_r[i]],i_dim)/v_s) # assign corresponding number of points to subregions\n",
    "        n_ss = n_s + n_model\n",
    "        samplegp = [[[0]*(n_ss)] for m in range(i_dim)]\n",
    "        for k in range(i_dim):\n",
    "            samplegp[k] = np.random.uniform(sub_r[i][k][0],sub_r[i][k][1],n_ss)\n",
    "            #np.apply_along_axis(lambda x: np.random.uniform(x[0], x[1], n), 2, sub_r)\n",
    "        sgp = [[[0]*i_dim] for p in range(n_ss)]\n",
    "        for l in range(n_ss):\n",
    "            sgp[l] = ([x[l] for x in samplegp])\n",
    "        y_pred_st, sigma_st = gp.predict(sgp, return_std=True)   ##predict new sample points\n",
    "        idxs = np.random.randint(0, n_s + n_model, n_model)##\n",
    "        y_pred = y_pred_st[idxs]\n",
    "        y_sigma = sigma_st[idxs]\n",
    "        for o in range(len(level)):\n",
    "            for e in range(y_pred_st):\n",
    "                level_quantile[i][o] = stats.norm.interval(0.96,mean,std) \n",
    "                y_pred_st - norm.ppf(level[o])*sigma_st\n",
    "        i_s = np.argmin(y_pred, axis=0)      #find maximum and minimum values of predicted values\n",
    "        i_ss = np.argmax(y_pred, axis=0) \n",
    "        #conf_intveral_1 = stats.norm.interval(1-alpha, loc=y_pred[i_s], scale=y_sigma[i_s])\n",
    "        #a = list(conf_intveral_1)\n",
    "        #lower.append(a[0])\n",
    "        #conf_intveral_2 = stats.norm.interval(1-alpha, loc=y_pred[i_ss], scale=y_sigma[i_ss])\n",
    "        #b = list(conf_intveral_2)\n",
    "        #upper.append(b[1])\n",
    "        sigma_s = max(y_sigma)\n",
    "        v_min = y_pred[i_s]-1.96*sigma_s   ##try to build the confidence interval\n",
    "        v_max = y_pred[i_ss] + 1.96*sigma_s\n",
    "        lower.append(v_min)\n",
    "        upper.append(v_max)\n",
    "    model_lower = np.array(lower)\n",
    "    model_upper = np.array(upper)\n",
    "    return model_lower, model_upper,level_quantile\n",
    "              \n",
    "def region_classify(lower: list, upper:list , sub_r:list, theta_undefined, theta_plus, theta_minus, tpn, tmn, tun):  \n",
    "    '''\n",
    "    classify the regions\n",
    "\n",
    "    Parameters:\n",
    "        lower(np.array): lower bounds of confidence intervals of each subregions\n",
    "        upper(np.array): lower bounds of confidence intervals of each subregions\n",
    "        sub_r(list): partitioned subregions\n",
    "\n",
    "       \n",
    "    Returns:\n",
    "        theta_plus, theta_minus, theta_undefined: classified regions\n",
    "        tpn, tmn, tun: number of classified region \n",
    "    '''\n",
    "    for i in range(0,len(lower)):\n",
    "        if lower[i]>0:\n",
    "            theta_plus.append(sub_r[i])\n",
    "            tpn.append(i)\n",
    "        elif upper[i]<0:\n",
    "            theta_minus.append(sub_r[i])\n",
    "            tmn.append(i)\n",
    "        else:\n",
    "            theta_undefined.append(sub_r[i])\n",
    "            tun.append(i)                                     \n",
    "    return theta_plus, theta_minus, theta_undefined,tpn, tmn, tun\n",
    "                                     \n",
    "def find_min(Y_subm,num,s: np.array,Y: list,i_dim:int) -> list:    #the minimum robustness values\n",
    "    '''\n",
    "    find minimum robustness values\n",
    "\n",
    "    Parameters:\n",
    "        s (np.array): Sample points\n",
    "        Y(list): robustness values\n",
    "        i_dim(int): the dimension of subregion\n",
    "\n",
    "    Returns:\n",
    "         num(list): the number of minmum points and corresponding robustness values\n",
    "         Y_subm(list): the minmum points\n",
    "\n",
    "    '''\n",
    "    Y_subm = [[] for i in range(len(s))]\n",
    "    num = [[0]*i_dim for i in range(len(s))]\n",
    "    for k in range(0,len(s)):\n",
    "        Y_subm[k] = min(Y[k])\n",
    "        inum = list(Y[k]).index(Y_subm[k])\n",
    "        num[k][0] = k\n",
    "        num[k][1] = inum\n",
    "    return num,Y_subm\n",
    "\n",
    "def part_percent(level:list, sub_r:list, v_s,level_quantile, p_quantile,i_dim: int):\n",
    "    '''\n",
    "    calculate falsification volume for each sub_regions\n",
    "\n",
    "    Parameters:\n",
    "        level(list): the quantile set\n",
    "        sub_r(list): the subregions\n",
    "        v_s: volume of the whole region\n",
    "        level_quantile: the predicted values to calculate fal_volume\n",
    "        i_dim(int): the dimension\n",
    "    Returns:\n",
    "        p_quantile(list): fal_volume for subregions\n",
    "    '''\n",
    "    for i in range(len(level)):\n",
    "        for j in range(len(sub_r)):\n",
    "            a_s = [x for x in level_quantile[j][i] if x < 0]\n",
    "            p_quantile[i]. append((len(a_s)/len(level_quantile[j][i]))*(vol([sub_r[j]],i_dim)/v_s))\n",
    "    return p_quantile\n",
    "\n",
    "def part_listc(i_dim, part_num, iteration):\n",
    "    l = []\n",
    "    k = []\n",
    "    for i in range(part_num, i_dim):\n",
    "        l.append(i)\n",
    "    for j in range(i_dim):\n",
    "        k.append(j)\n",
    "    part_index = k*round((iteration-part_num)/i_dim)\n",
    "    part_list = l + part_index\n",
    "    return part_list\n",
    "\n",
    "def fun_reg_branching(sl_coordinate_lower: np.ndarray, sl_coordinate_upper: np.ndarray, i_dim: int, i_B: int, sub_r, sub_u: list, part_list:list, z: int,list_subr) -> list:\n",
    "    '''\n",
    "    Partitioning Algorithm\n",
    "    Parameters:\n",
    "        [np.ndarray, np.ndarray]: tuple of MxNx1 that are the separated upper and lower bounds\n",
    "        i_dim(int):dimension\n",
    "        sub_u(list): defined region\n",
    "        part_list(list): the list to instruct the partition\n",
    "        iteration(int): which itertion\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "        sub_r(list): sub-regions\n",
    "    '''\n",
    "    assert sl_coordinate_lower.ndim == 2, 'sl_coordinate_lower matrix must be 2 dimensional'\n",
    "    assert sl_coordinate_upper.ndim == 2, 'sl_coordinate_upper matrix must be 2 dimensional'\n",
    "    sl_coordinate_upper = sl_coordinate_upper.tolist()\n",
    "    sl_coordinate_lower = sl_coordinate_lower.tolist()\n",
    "    list_star = [[] for i in range(2*len(sub_u))]\n",
    "    for j in range(len(sub_u)):\n",
    "        m = (np.array(sl_coordinate_upper[j]) - np.array(sl_coordinate_lower[j])).tolist()\n",
    "        #f_value = choice(m)\n",
    "        #i_index = m.index(f_value)\n",
    "        i_index = part_list[z]\n",
    "        for i in range(0, i_B):\n",
    "            l_coordinate_lower = copy.deepcopy(sl_coordinate_lower)\n",
    "            l_coordinate_upper = copy.deepcopy(sl_coordinate_upper)\n",
    "            l_coordinate_lower[j][i_index] = float((sl_coordinate_upper[j][i_index] - sl_coordinate_lower[j][i_index]) * i) / i_B + sl_coordinate_lower[j][i_index]\n",
    "            l_coordinate_upper[j][i_index] = float((sl_coordinate_upper[j][i_index] - sl_coordinate_lower[j][i_index]) * (i + 1)) / i_B + sl_coordinate_lower[j][i_index]\n",
    "            a = [[0]*2 for i in range(0, i_dim)]\n",
    "            for i in range(0, i_dim):\n",
    "                a[i][0] = l_coordinate_lower[j][i]\n",
    "                a[i][1] = l_coordinate_upper[j][i]\n",
    "            sub_r.append(a)\n",
    "            list_star[2*j] = 2*(list_subr[j]) -1\n",
    "            list_star[2*j+1] = 2*(list_subr[j])\n",
    "                \n",
    "\n",
    "    return sub_r,list_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    " Part_classify(sub_u: list, i_dim: int, i_B: int, alpha: float, test_function: Callable[[], float], \n",
    "               n:int,level:list,replication:int, iteration: int,min_volume:float,max_budget:int, fal_num: float,n_model: int,n_bo:int, n_b:int, sample_method,part_num:int):\n",
    "    '''\n",
    "    algorithm\n",
    "\n",
    "    Parameters:\n",
    "        sub_u(list): region\n",
    "        i_dim(int): dimension of the region\n",
    "        i_B: # of partition (default = 2)\n",
    "        alpha(float): miscoverage level\n",
    "        test_function: the callable function \n",
    "        n(int): the number of uniform sampling for each subregions\n",
    "        level(list): the list of quantile of falsification volume (ex: [0.5,0.7])\n",
    "        replication(int): number of replication\n",
    "        iteration(int): number of iteration for each replication (default = 100)\n",
    "        min_volume(float): stop condition of the volume (default = 0.001)\n",
    "        max_budget(int): number of max budget for one replication\n",
    "        fal_num (int): the number of sample points to calculate the falsification volume\n",
    "        n_model(int): number of sample points to do the GP prediction to construct the CI\n",
    "        n_bo(int): number of Bayesian Optimization sampling\n",
    "        n_b(int): number of points to construct GPs in BO (default = 100)\n",
    "        sample_method(str): 'BO sampling' or 'uniform sampling'\n",
    "        \n",
    "    Returns:\n",
    "        iteration(list): iteration numbers to finish one replication\n",
    "        percentage of defined region(list): percentage of volume of theta_plus+theta_minus over the volume of whole region for each iteration\n",
    "        percentage of theta_plus (list): percentage of volume of theta_plus over the volume of whole region for each iteration\n",
    "        percentage of theta_minus(list): percentage of volume of theta_minus over the volume of whole region for each iteration\n",
    "        theta_plus(list): theta_plus( the regions satisfy trajectory)\n",
    "        theta_minus(list): theta_minus( the regions violate trajectory)\n",
    "        theta_undefined(list): the regions remain to be defined\n",
    "        falsidication volumes(list): the falsification volume for each quantile\n",
    "        budgets(list): overall budget for one replication\n",
    "        budgets for each iteration(list): budget of each iteration for one replication\n",
    "        falsification volume for each iteration(list): the falsification volume for each quantile of each iteration\n",
    "        The minimum robustness value(list): minimum robustness value of one repliacation\n",
    "        The minimum robustness value corresponding point(list): the corresponding sanple point\n",
    "        percentage of falsifying points of robustness values(list): for each iteration, the percentage of negative robustness values\n",
    "    \n",
    "    '''\n",
    "    P = []\n",
    "    K = []\n",
    "    TPP = []\n",
    "    TMP = []\n",
    "    TMV = []\n",
    "    TPV = []\n",
    "    TUV = []\n",
    "    H = []\n",
    "    evl = []\n",
    "    p_iter=[]\n",
    "    v_s = vol(sub_u,i_dim)\n",
    "    region = sub_u\n",
    "    #print(v_s)\n",
    "    S=[]\n",
    "    # count = i\n",
    "    t_fal = []\n",
    "    X_minf = []\n",
    "    Y_minf = []\n",
    "    number_subregion = []\n",
    "    part_list = part_listc(i_dim, part_num, iteration)\n",
    "    for q in range(replication):  #CHANGE FOR MORE REPLICATION\n",
    "        sub_u = region\n",
    "        print(\"runtime:\",q+1)\n",
    "        theta_plus=[]\n",
    "        theta_minus=[]\n",
    "        V=[]\n",
    "        TP=[]\n",
    "        TM=[]\n",
    "        budgets = []\n",
    "        D=0\n",
    "        p_fal = [[] for j in range(len(level))]\n",
    "        fal_iter = [[] for j in range(len(level))]\n",
    "        z=0\n",
    "        Y_min = []\n",
    "        X_min = []\n",
    "        True_fal = []\n",
    "        number_sub = []\n",
    "        v_min = [vol(sub_u,i_dim)]\n",
    "        d1 = 0\n",
    "        d2 = 0\n",
    "        list_subr = [1]\n",
    "        #TP_iter = []\n",
    "        #TM_iter = []\n",
    "        #TU_iter = []\n",
    "        for z in range(iteration):  ##change for iteration\n",
    "            v = vol(sub_u,i_dim)\n",
    "            if min(v_min) > min_volume*v_s and D < max_budget: #0.01: #v(sub_u)\n",
    "                sl_coordinate_lower, sl_coordinate_upper = sl(sub_u,i_dim)\n",
    "                sub_r = []\n",
    "                sub_r, list_star = fun_reg_branching(sl_coordinate_lower, sl_coordinate_upper, i_dim, i_B, \n",
    "                                                     sub_r, sub_u, part_list,z,list_subr)\n",
    "                s_p = [[] for i in range(len(sub_r))]############\n",
    "                Y_p = [[] for i in range(len(sub_r))]###########\n",
    "                s_p, Y_p = tell_sample(X_all, Y_all, sub_r,i_dim,z,s_p,Y_p)#########\n",
    "                sample = sample_g(sub_r, n,i_dim)\n",
    "                s=[[[0]*i_dim]*n for i in range(len(sub_r))]\n",
    "                s,X_all = sam(sub_r, n, sample, s,s_p)#########\n",
    "                Y = []\n",
    "                Y,Y_all = g(s, Y, test_function,Y_p)############\n",
    "                if sample_method =='BO Sampling':\n",
    "                    s_bo, Y,s_bo_all, Y_all = Bayesian_optimization(s , Y, n_bo,i_dim,sub_r,test_function,n_b)\n",
    "                    s = s_bo\n",
    "                    X_all = s_bo_all\n",
    "                sub_all = []##########\n",
    "                number_all = []########\n",
    "                for p in range(len(s)):#############\n",
    "                    sub_all.append([sub_r[p]]*len(s[p]))################\n",
    "                    number_all.append(list_star[p]*len(s[p]))##############\n",
    "        \n",
    "                tf = [x for x in Y_all if x < 0]\n",
    "                if tf != []:\n",
    "                    True_fal.append(len(tf)/len(Y_all))\n",
    "                else: \n",
    "                    True_fal.append(0)\n",
    "                #print(true_fal)\n",
    "                Y_subm = [[] for i in range(len(s))]\n",
    "                num = [[0]*i_dim for i in range(len(s))]\n",
    "                num_min = []\n",
    "                num, Y_subm = find_min(Y_subm,num,s,Y,i_dim)\n",
    "                kf = Y_subm.index(min(Y_subm))\n",
    "                num_min.append(num[kf])\n",
    "                X_min.append(s[num_min[0][0]][num_min[0][1]])\n",
    "                Y_min.append(min(Y_subm))\n",
    "                lower=[]\n",
    "                upper=[]\n",
    "                model_lower, model_upper,level_quantile = model_construction(s, Y, v_s, sub_r, lower, upper, level, z, q, i_dim, fal_num, n_model,alpha,list_star)\n",
    "                #print(level_quantile)\n",
    "                p_quantile = [[] for i in range(len(level))]\n",
    "                p_quantile = part_percent(level, sub_r, v_s,level_quantile, p_quantile,i_dim)\n",
    "                theta_undefined=[]\n",
    "                tpn = []\n",
    "                tmn = []\n",
    "                tun = []\n",
    "                theta_plus, theta_minus, theta_undefined, tpn, tmn, tun = region_classify(lower, upper , sub_r, theta_undefined, theta_plus, theta_minus, tpn, tmn, tun)\n",
    "                tp =[]\n",
    "                theta_d = []\n",
    "                v_min = []\n",
    "                theta = theta_undefined+theta_plus+theta_minus\n",
    "            \n",
    "                #print(theta_plus)\n",
    "                #print(theta_minus)\n",
    "                #print(theta_undefined)\n",
    "                #print(theta)\n",
    "                if len(theta_undefined) != 0:\n",
    "                    for i in range(len(theta)):\n",
    "                        v_min.append(vol([theta[i]],i_dim))\n",
    "                if len(theta_undefined) == 0:\n",
    "                    v_min.append(0)\n",
    "                D += len(sub_r) * (n+n_bo)\n",
    "                if min(v_min) < min_volume*v_s or D >= max_budget:\n",
    "                    tp = tpn+tmn+tun\n",
    "                if min(v_min) > min_volume*v_s and D < max_budget:\n",
    "                    tp = tpn+tmn\n",
    "                Z = []\n",
    "                Q = []\n",
    "                list_region = []\n",
    "                if len(tp)!= 0:\n",
    "                    Z = [z+1]*len(tp)\n",
    "                    Q = [q+1]*len(tp)\n",
    "                for i in range(len(tp)):\n",
    "                    if len(tp)!=0:\n",
    "                        theta_d.append(sub_r[tp[i]])\n",
    "                        list_region.append(list_star[tp[i]])\n",
    "                        for j in range(len(level)):\n",
    "                            p_fal[j].append(p_quantile[j][tp[i]])\n",
    "                number_sub.append(list_region)\n",
    "                for m in range(len(list_region)):\n",
    "                    shutil.move( '/Users/candicetsao/Desktop/sin_gp/models/'+'trainmodel'+str(0)+str(q+1)+str(0)+str(z+1) + str(0)+str(list_region[m])+'.m', '/Users/candicetsao/Desktop/sin_gp/all_gp_result')  \n",
    "                    \n",
    "                subregion = pd.DataFrame({'subregion': theta_d,'replication': Q,'deepth': Z,'number':list_region})\n",
    "                subregion.to_csv('/Users/candicetsao/Desktop/sin_gp/subregions.csv', mode='a', header=False)\n",
    "                points = pd.DataFrame({'X': X_all,'Y': Y_all, subregion: sub_all, 'replication': Q,'deepth': Z,'number':number_all})##############\n",
    "                points.to_csv('/Users/candicetsao/Desktop/sin_gp/points'+str(q+1)+'.csv', mode = 'a', index=False,sep=',',header =False)################\n",
    "                list_subr = [x for x in list_star if x not in list_region]\n",
    "                #print(v_min)\n",
    "                #x_s = []\n",
    "                #y_s = []\n",
    "                for i in range(len(level)):\n",
    "                    fal_iter[i].append(sum(p_quantile[i]))\n",
    "                #print(fal_iter)\n",
    "                if len(theta_plus)!= 0:\n",
    "                     d1 = vol(theta_plus,i_dim)\n",
    "                if len(theta_minus)!= 0:\n",
    "                    d2 = vol(theta_minus,i_dim)\n",
    "                d = d1 + d2\n",
    "                #print(d)\n",
    "                V.append(d/v_s)\n",
    "                TP.append(d1/v_s)\n",
    "                TM.append(d2/v_s)\n",
    "                budgets.append(len(sub_r))\n",
    "    #             print(S)\n",
    "                if theta_undefined !=[]:\n",
    "                    sub_u = theta_undefined\n",
    "                else:\n",
    "                    sub_u = sub_r\n",
    "            else:\n",
    "                fal_v = [[] for i in range(len(level))]\n",
    "                for i in range(len(level)):\n",
    "                    fal_v[i]= sum(p_fal[i])\n",
    "                TMV.append(theta_minus)\n",
    "                TPV.append(theta_plus)\n",
    "                TUV.append(theta_undefined)\n",
    "                S.append(D)\n",
    "                P.append(z)\n",
    "                K.append(V)\n",
    "                TPP.append(TP)\n",
    "                TMP.append(TM)\n",
    "                H.append(fal_v)\n",
    "                evl.append(budgets) ``\n",
    "                p_iter.append(fal_iter)\n",
    "                dk = Y_min.index(min(Y_min))\n",
    "                t_fal.append(True_fal)\n",
    "                X_minf.append(X_min[dk])\n",
    "                Y_minf.append(min(Y_min))\n",
    "                number_subregion.append(number_sub)\n",
    "                break\n",
    "    print('iteration:',P)   # replication time\n",
    "    #print(S)   # budgets for each time\n",
    "    print('percentage of defined region:',K)    # Volume of theta_plus+theta_minus\n",
    "    print(\"---------------------------------------\")\n",
    "    print('percentage of theta_plus:',TPP)  #Volume of theta_plus\n",
    "    print(\"---------------------------------------\")\n",
    "    print('percentage of theta_minus:',TMP)   #Volume of theta_minus\n",
    "    print(\"---------------------------------------\")\n",
    "    print('theta_plus:',TPV)\n",
    "    print(\"---------------------------------------\")\n",
    "    print('theta_minus:',TMV)\n",
    "    print(\"---------------------------------------\")\n",
    "    print('theta_undefined:',TUV)\n",
    "    print(\"---------------------------------------\")\n",
    "    print('falsification volumes:', H)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"budgets:\", S)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"budgets for each iteration:\", evl)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"falsification volume for each iteration:\", p_iter)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"The minimum robustness value:\", Y_minf)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"The minimum robustness value corresponding point:\", X_minf)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"percentage of falsifying points of robustness values:\",t_fal)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"number of defined region:\",number_subregion)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return TPV,TMV,TUV, S, H, evl, p_iter, number_subregion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
